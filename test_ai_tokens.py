#!/usr/bin/env python3
"""
üß™ –¢–µ—Å—Ç AI —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É Ollama, OpenAI –∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ AI
"""
import os
import sys
import requests
import json
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

def test_ollama():
    """–¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Ollama...")
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            available_models = [m['name'] for m in models]
            print(f"‚úÖ Ollama –¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª–∏: {available_models}")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            if available_models:
                test_model = "tinyllama:latest"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–±–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
                data = {
                    "model": test_model,
                    "prompt": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
                    "stream": False,
                    "options": {"num_predict": 50}
                }
                
                gen_response = requests.post(
                    "http://localhost:11434/api/generate",
                    json=data,
                    timeout=15
                )
                
                if gen_response.status_code == 200:
                    result = gen_response.json()
                    ai_text = result.get('response', '').strip()
                    print(f"‚úÖ Ollama –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: {ai_text[:50]}...")
                    return True
                else:
                    print(f"‚ùå Ollama –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—à–∏–±–∫–∞: {gen_response.status_code}")
            else:
                print("‚ö†Ô∏è Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π")
        else:
            print(f"‚ùå Ollama –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç: {response.status_code}")
    except Exception as e:
        print(f"‚ùå Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
    return False

def test_openai():
    """–¢–µ—Å—Ç OpenAI API"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ OpenAI...")
    try:
        api_key = os.getenv('OPENAI_API_KEY')
        
        if not api_key:
            print("‚ùå OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env")
            return False
            
        if api_key == "dummy_key_for_testing":
            print("‚ö†Ô∏è OpenAI –∫–ª—é—á —è–≤–ª—è–µ—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–º (dummy_key_for_testing)")
            return False
            
        if not api_key.startswith('sk-'):
            print(f"‚ùå OpenAI –∫–ª—é—á –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π: {api_key[:10]}... (–¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'sk-')")
            return False
            
        print(f"‚úÖ OpenAI –∫–ª—é—á –Ω–∞–π–¥–µ–Ω: {api_key[:10]}...{api_key[-4:]}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º API
        headers = {
            'Authorization': f'Bearer {api_key}',
            'Content-Type': 'application/json'
        }
        
        data = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": "–¢—ã HR-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ."},
                {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞ —Å —Ä–∞–±–æ—Ç–æ–π?"}
            ],
            "max_tokens": 50,
            "temperature": 0.7
        }
        
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            ai_text = result['choices'][0]['message']['content'].strip()
            print(f"‚úÖ OpenAI API —Ä–∞–±–æ—Ç–∞–µ—Ç: {ai_text[:50]}...")
            return True
        else:
            print(f"‚ùå OpenAI API –æ—à–∏–±–∫–∞ {response.status_code}:")
            try:
                error_info = response.json()
                print(f"   {error_info.get('error', {}).get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            except:
                print(f"   {response.text[:200]}")
                
    except Exception as e:
        print(f"‚ùå OpenAI –æ—à–∏–±–∫–∞: {e}")
    return False

def test_local_ai():
    """–¢–µ—Å—Ç –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ AI (fallback)"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ AI...")
    
    # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–∫–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞
    user_input = "–•–æ—á—É —Ä–∞–±–æ—Ç–∞—Ç—å –≤ IT"
    
    if "it" in user_input.lower():
        response = "IT-—Å—Ñ–µ—Ä–∞ –æ—á–µ–Ω—å –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–∞! –†–µ–∫–æ–º–µ–Ω–¥—É—é –∏–∑—É—á–∏—Ç—å Python –∏–ª–∏ JavaScript."
    else:
        response = "–ü–æ–Ω–∏–º–∞—é –≤–∞—à –∏–Ω—Ç–µ—Ä–µ—Å –∫ –∫–∞—Ä—å–µ—Ä–µ. –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ –æ –≤–∞—à–∏—Ö —Ü–µ–ª—è—Ö."
    
    print(f"‚úÖ –õ–æ–∫–∞–ª—å–Ω—ã–π AI —Ä–∞–±–æ—Ç–∞–µ—Ç: {response}")
    return True

def test_env_file():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ .env —Ñ–∞–π–ª–∞"""
    print("üß™ –ü—Ä–æ–≤–µ—Ä–∫–∞ .env —Ñ–∞–π–ª–∞...")
    
    env_file = ".env"
    if not os.path.exists(env_file):
        print("‚ö†Ô∏è .env —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False
    
    print("‚úÖ .env —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    with open(env_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–π
    required_keys = ['BOT_TOKEN', 'OPENAI_API_KEY', 'ADMIN_CHAT_ID']
    found_keys = []
    
    for key in required_keys:
        if key in content:
            found_keys.append(key)
            value = os.getenv(key, '–ù–ï –ù–ê–ô–î–ï–ù')
            if key == 'OPENAI_API_KEY':
                # –ú–∞—Å–∫–∏—Ä—É–µ–º API –∫–ª—é—á
                masked_value = f"{value[:10]}...{value[-4:]}" if len(value) > 14 else value
                print(f"  ‚úÖ {key}: {masked_value}")
            else:
                print(f"  ‚úÖ {key}: {value}")
        else:
            print(f"  ‚ùå {key}: –ù–ï –ù–ê–ô–î–ï–ù")
    
    return len(found_keys) == len(required_keys)

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ AI —Å–∏—Å—Ç–µ–º –¥–ª—è HR-–ü—Å–∏—Ö–æ–∞–Ω–∞–ª–∏—Ç–∏–∫–∞\n")
    
    # –¢–µ—Å—Ç—ã
    env_ok = test_env_file()
    ollama_ok = test_ollama()
    openai_ok = test_openai() 
    local_ok = test_local_ai()
    
    print("\n" + "="*50)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
    print("="*50)
    
    print(f"üìÅ .env –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {'‚úÖ OK' if env_ok else '‚ùå FAIL'}")
    print(f"üß† Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π): {'‚úÖ OK' if ollama_ok else '‚ùå FAIL'}")
    print(f"ü§ñ OpenAI API: {'‚úÖ OK' if openai_ok else '‚ùå FAIL'}")
    print(f"üí° –õ–æ–∫–∞–ª—å–Ω—ã–π AI: {'‚úÖ OK' if local_ok else '‚ùå FAIL'}")
    
    print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    
    if ollama_ok:
        print("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Ollama –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –ª–æ–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤")
    else:
        print("‚ö†Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç–µ Ollama: ollama serve")
        print("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª—å: ollama pull llama2")
    
    if openai_ok:
        print("‚úÖ OpenAI API –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    else:
        print("‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—å—Ç–µ OPENAI_API_KEY –≤ .env —Ñ–∞–π–ª–µ")
        print("‚ö†Ô∏è –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –∫–ª—é—á –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 'sk-'")
        print("‚ö†Ô∏è –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –±–∞–ª–∞–Ω—Å –Ω–∞ https://platform.openai.com/usage")
    
    if not ollama_ok and not openai_ok:
        print("‚ö†Ô∏è –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ç–æ–ª—å–∫–æ –ª–æ–∫–∞–ª—å–Ω—ã–π AI (–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏)")
    
    print("\nüéâ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞
    if openai_ok or ollama_ok:
        return 0  # –£—Å–ø–µ—Ö
    else:
        return 1  # –ü—Ä–æ–±–ª–µ–º—ã

if __name__ == "__main__":
    sys.exit(main())
