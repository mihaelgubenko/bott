#!/usr/bin/env python3
"""
–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –¥–ª—è main.py: –¥–æ–±–∞–≤–ª—è–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç—Å—è —Å TinyLlama –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫–æ–º
"""
import logging
import os
import requests
import tempfile
import subprocess
from telegram import Update
from telegram.ext import ContextTypes, MessageHandler, filters

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à AI –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫
import sys
sys.path.append('.')

logger = logging.getLogger(__name__)

class VoiceHandler:
    def __init__(self):
        self.ai_server_url = "http://localhost:8765"  # WebSocket —Å–µ—Ä–≤–µ—Ä
        self.simple_api_url = "http://localhost:8001"  # –ü—Ä–æ—Å—Ç–æ–π API
        self.ollama_path = r'C:\Users\mihae\AppData\Local\Programs\Ollama\ollama.exe'
        
    async def handle_voice_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        user = update.effective_user
        voice = update.message.voice
        
        logger.info(f"üì¢ –ü–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user.first_name} (ID: {user.id})")
        
        # –£–≤–µ–¥–æ–º–ª—è–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        status_msg = await update.message.reply_text("üé§ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
        
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            voice_file = await context.bot.get_file(voice.file_id)
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix=".oga", delete=False) as tmp_file:
                await voice_file.download_to_drive(tmp_file.name)
                voice_path = tmp_file.name
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            wav_path = voice_path.replace(".oga", ".wav")
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º ffmpeg –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (–µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω)
                subprocess.run([
                    'ffmpeg', '-i', voice_path, '-ar', '16000', '-ac', '1', wav_path
                ], check=True, capture_output=True)
                audio_path = wav_path
            except (subprocess.CalledProcessError, FileNotFoundError):
                # –ï—Å–ª–∏ ffmpeg –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
                audio_path = voice_path
            
            # –°–∏–º—É–ª–∏—Ä—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (–∑–∞–≥–ª—É—à–∫–∞)
            recognized_text = await self.simulate_speech_recognition(audio_path)
            
            await status_msg.edit_text(f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: \"{recognized_text}\"\n\nü§ñ AI –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç...")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ AI –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            ai_response = await self.get_ai_response(recognized_text, user.id)
            
            # –û—Ç–≤–µ—á–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            await status_msg.edit_text(
                f"üé§ **–í–∞—à–µ —Å–æ–æ–±—â–µ–Ω–∏–µ:** {recognized_text}\n\n"
                f"ü§ñ **AI –æ—Ç–≤–µ—Ç:** {ai_response}"
            )
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
            try:
                voice_response = await self.generate_voice_response(ai_response)
                if voice_response:
                    await update.message.reply_voice(voice_response)
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç: {e}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
            await status_msg.edit_text(
                "‚ùå –ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. "
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
            )
        finally:
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            try:
                if 'voice_path' in locals():
                    os.unlink(voice_path)
                if 'wav_path' in locals() and os.path.exists(wav_path):
                    os.unlink(wav_path)
            except:
                pass
    
    async def simulate_speech_recognition(self, audio_path):
        """–°–∏–º—É–ª—è—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏"""
        # –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Ñ—Ä–∞–∑ –¥–ª—è —Å–∏–º—É–ª—è—Ü–∏–∏
        sample_phrases = [
            "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
            "–ß—Ç–æ —Ç—ã —É–º–µ–µ—à—å –¥–µ–ª–∞—Ç—å?",
            "–†–∞—Å—Å–∫–∞–∂–∏ –æ —Å–µ–±–µ",
            "–ö–∞–∫ —Ç–µ–±—è –∑–æ–≤—É—Ç?",
            "–ö–∞–∫–∞—è —Å–µ–≥–æ–¥–Ω—è –ø–æ–≥–æ–¥–∞?",
            "–ü–æ–º–æ–≥–∏ –º–Ω–µ —Å –≤—ã–±–æ—Ä–æ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏",
            "–ü—Ä–æ–≤–µ–¥–∏ –∞–Ω–∞–ª–∏–∑ –ª–∏—á–Ω–æ—Å—Ç–∏",
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å",
            "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è"
        ]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ—Ä–∞–∑—É –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ–∞–π–ª–∞ (–ø—Ä–æ—Å—Ç–∞—è —Å–∏–º—É–ª—è—Ü–∏—è)
        try:
            file_size = os.path.getsize(audio_path)
            phrase_index = file_size % len(sample_phrases)
            return sample_phrases[phrase_index]
        except:
            return "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á—Ç–æ-—Ç–æ —Å–∫–∞–∑–∞–ª"
    
    async def get_ai_response(self, text, user_id):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç AI –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫–∞"""
        try:
            # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π API
            response = requests.post(
                f"{self.simple_api_url}/chat",
                json={"message": text, "caller_id": str(user_id)},
                timeout=15
            )
            
            if response.status_code == 200:
                data = response.json()
                return data.get("response", "–°–ø–∞—Å–∏–±–æ –∑–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ!")
            else:
                raise Exception(f"API error: {response.status_code}")
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ API: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ Ollama")
            
            # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ TinyLlama
            try:
                prompt = f"–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –∫–∞–∫ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫: {text}"
                result = subprocess.run([
                    self.ollama_path, 'run', 'tinyllama', prompt
                ], capture_output=True, text=True, timeout=10, encoding='utf-8', errors='ignore')
                
                if result.returncode == 0:
                    response = result.stdout.strip()
                    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
                    if len(response) > 200:
                        response = response[:200] + "..."
                    return response if response else "–ü–æ–Ω—è–ª –≤–∞—Å!"
                else:
                    return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–µ–π—á–∞—Å –Ω–µ –º–æ–≥—É –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ç–µ–∫—Å—Ç–æ–º."
                    
            except Exception as e2:
                logger.error(f"–û—à–∏–±–∫–∞ Ollama: {e2}")
                return "–°–ø–∞—Å–∏–±–æ –∑–∞ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ! –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ–∫—Å—Ç–æ–º."
    
    async def generate_voice_response(self, text):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å espeak
            result = subprocess.run(['espeak', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode != 0:
                return None
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è –∞—É–¥–∏–æ
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_file:
                wav_path = tmp_file.name
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º espeak –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
            subprocess.run([
                'espeak', 
                '-s', '150',      # —Å–∫–æ—Ä–æ—Å—Ç—å
                '-v', 'ru',       # —Ä—É—Å—Å–∫–∏–π –≥–æ–ª–æ—Å
                '-w', wav_path,   # –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª
                text[:100]        # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            ], check=True, timeout=10)
            
            # –ß–∏—Ç–∞–µ–º –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—É–¥–∏–æ
            with open(wav_path, 'rb') as f:
                audio_data = f.read()
            
            # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            os.unlink(wav_path)
            
            return audio_data
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞: {e}")
            return None

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞
voice_handler = VoiceHandler()

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ main.py
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ main.py"""
    await voice_handler.handle_voice_message(update, context)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –≤–∏–¥–µ–æ-—Å–æ–æ–±—â–µ–Ω–∏–π (–∫—Ä—É–≥–ª—ã–µ –≤–∏–¥–µ–æ)
async def handle_video_note(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫—Ä—É–≥–ª—ã—Ö –≤–∏–¥–µ–æ-—Å–æ–æ–±—â–µ–Ω–∏–π"""
    user = update.effective_user
    await update.message.reply_text(
        f"üé• {user.first_name}, —è –ø–æ–∫–∞ –Ω–µ —É–º–µ—é –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤–∏–¥–µ–æ-—Å–æ–æ–±—â–µ–Ω–∏—è. "
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–∫—Å—Ç–æ–º!"
    )

# –¢–µ—Å—Ç–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def test_voice_system():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤–æ–π —Å–∏—Å—Ç–µ–º—ã"""
    handler = VoiceHandler()
    
    # –¢–µ—Å—Ç AI –æ—Ç–≤–µ—Ç–∞
    test_text = "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?"
    response = await handler.get_ai_response(test_text, 12345)
    print(f"–¢–µ—Å—Ç AI: '{test_text}' -> '{response}'")
    
    # –¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
    voice_data = await handler.generate_voice_response("–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?")
    if voice_data:
        print(f"–ì–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {len(voice_data)} –±–∞–π—Ç")
    else:
        print("–ì–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")

if __name__ == "__main__":
    import asyncio
    asyncio.run(test_voice_system())
